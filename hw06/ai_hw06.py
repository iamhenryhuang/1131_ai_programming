# -*- coding: utf-8 -*-
"""ai_hw06.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oDf9JoFyNFV-i5ud4iwFIMKcZsm9i4Au

環境設定
"""

# Install HappyML
import os

if not os.path.isdir("HappyML"):
  os.system("git clone https://github.com/cnchi/HappyML.git")

from tensorflow.keras.datasets import cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Validate the Success of Image Loading
import HappyML.model_drawer as md

# Print the first 10 images of Training Set
md.show_first_n_images(x_ary=x_train, y_real=y_train, first_n=10, font_size=12)

# Print the first 10 images of Testing Set
md.show_first_n_images(x_ary=x_test, y_real=y_test, first_n=10, font_size=12)

"""對應變數 Y 進行前處理"""

# One-Hot Encoding for Y
from tensorflow.keras.utils import to_categorical

num_classes = 10
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

"""照片前處理"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1.0/255,
    validation_split=0.25,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=10,
    zoom_range=0.2,
    horizontal_flip=True
)

train_set = train_datagen.flow(
    x_train, y_train,
    batch_size=10,
    subset="training"
)

val_set = train_datagen.flow(
    x_train, y_train,
    batch_size=10,
    subset="validation"
)

test_datagen = ImageDataGenerator(
    rescale=1.0/255
)

test_set = test_datagen.flow(
    x_test, y_test,
    batch_size=32)

"""建造卷積神經網路"""

from tensorflow.keras.models import Sequential
from tensorflow.keras import layers, Input
from tensorflow.keras.optimizers import RMSprop

# CNN Model
model = Sequential()

# Input Layer
model.add(Input(shape=[32, 32, 3]))

# 1st Hidden Layer: Convolutional + Max Pooling
model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation="relu", padding="same"))
model.add(layers.Dropout(0.25))
model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))

# 2nd Hidden Layer: Convolutional + Max Pooling
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation="relu", padding="same"))
model.add(layers.Dropout(0.25))
model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))

# 3rd Hidden Layer: Convolutional + Max Pooling
model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation="relu", padding="same"))
model.add(layers.Dropout(0.25))
model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))

# Flatten layer
model.add(layers.Flatten())

# Fully Connected Layer
model.add(layers.Dense(units=1024, activation="relu"))

# Output layer
model.add(layers.Dense(units=10, activation="softmax"))

# Compile
model.compile(optimizer=RMSprop(learning_rate=1e-4), loss="categorical_crossentropy", metrics=["accuracy"])

"""模型校正"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# Create TensorBoard log directory
import os
from datetime import datetime
from tensorflow.keras.callbacks import TensorBoard

logdir = os.path.join("logs", datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = TensorBoard(logdir, histogram_freq=1)

# Commented out IPython magic to ensure Python compatibility.
# Start the TensorBoard
# %tensorboard --logdir logs

# --- For TensorBoard 403 Error ---
# Start the TensorBoard (Ignore the errors)
# %tensorboard --logdir logs --host=127.0.0.1 --port=6006 --load_fast=false

# Workaround for loading TensorBoard
# from google.colab import output
# output.serve_kernel_port_as_window(6006, path="")

# Training Model
epochs_metrics = model.fit(train_set, validation_data=val_set, batch_size=10, epochs=25, callbacks=[tensorboard_callback])

"""模型訓練"""

# Model Training (After Tuning)
epochs_metrics = model.fit(train_set, validation_data=val_set, batch_size=10, epochs=8)

"""模型預測"""

import numpy as np

y_pred = np.argmax(model.predict(x_test), axis=1)
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
md.show_first_n_images(x_ary=x_test, y_real=y_test, y_pred=y_pred[:10], first_n=10, font_size=12)

"""模型評估"""

test_loss, test_acc = model.evaluate(test_set)
print("Loss of Test:", test_loss)
print("Accuracy of Test:", test_acc)
