# -*- coding: utf-8 -*-
"""ai_hw05.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P-aHONdsgxd2lXu-2Tg1njsbnMavmbj8

載入套件
"""

import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import TensorBoard
import numpy as np
from datetime import datetime

"""取得資料集"""

Dataset_File = "Glass.csv"
if not os.path.isfile(Dataset_File):
    os.system("wget https://raw.githubusercontent.com/cnchi/datasets/master/" + Dataset_File)

data = pd.read_csv(Dataset_File)

"""提取特徵與標籤

"""

X = data.iloc[:, :-1].values  # 提取特徵
Y = data.iloc[:, -1].values   # 提取標籤 (第 1～7 等)

"""類別資料數位化"""

# 類別編碼
label_encoder = LabelEncoder()
Y = label_encoder.fit_transform(Y)  # 將 1～7 的數字轉為索引值 (0～6)

# One-hot 編碼
onehot_encoder = OneHotEncoder(sparse_output=False)  # 注意這裡改成 sparse_output=False
Y = onehot_encoder.fit_transform(Y.reshape(-1, 1))

"""切分訓練集、測試集與特徵縮放"""

# 分割資料
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# 特徵縮放
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""模型建置"""

model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # 第一隱藏層
    Dense(32, activation='relu'),  # 第二隱藏層
    Dense(Y_train.shape[1], activation='softmax')  # 輸出層 (7 類別)
])

"""編譯模型"""

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

"""訓練模型"""

model.fit(x=X_train,
     y=Y_train,
     validation_split=0.2,
     batch_size=16,
     epochs=50,
     callbacks=[tensorboard_callback])

"""設定 TensorBoard"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

# Create TensorBoard log directory
import os
from datetime import datetime
from tensorflow.keras.callbacks import TensorBoard

logdir = os.path.join("logs", datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = TensorBoard(logdir, histogram_freq=1)

# Commented out IPython magic to ensure Python compatibility.
# Start the TensorBoard
# %tensorboard --logdir logs

"""預測結果"""

Y_pred = model.predict(X_test)
Y_pred_classes = np.argmax(Y_pred, axis=1)  # 將預測結果轉為類別索引
Y_test_classes = np.argmax(Y_test, axis=1)  # 測試集真實類別

df = pd.DataFrame({
    'Actual': Y_test_classes,
    'Predicted': Y_pred_classes
})

# 隨機選取 15 筆資料
df_sample = df.sample(n=15)  # random_state 用於結果可重現性

print(df_sample)

"""模型評估"""

test_loss, test_acc = model.evaluate(X_test, Y_test)
print("Loss of Testing Set:", test_loss)
print("Accuracy of Testing Set:", test_acc)