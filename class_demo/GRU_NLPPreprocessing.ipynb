{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "h_C_oh5CjGYN",
        "PFDkjdHnwYRT",
        "SnmGItjN079S",
        "v1SyEADl53UB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 斷詞"
      ],
      "metadata": {
        "id": "h_C_oh5CjGYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 英文斷詞"
      ],
      "metadata": {
        "id": "TdmLSRLusHZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "looMlRdbh0Cp",
        "outputId": "2fb40509-464d-4aac-e102-ce5a5d8c7f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "英文斷詞： ['i', 'love', 'jogging', 'and', 'you']\n"
          ]
        }
      ],
      "source": [
        "# 英文斷詞\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "print(\"英文斷詞：\", text_to_word_sequence(\"I love jogging, and you?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 中文斷詞"
      ],
      "metadata": {
        "id": "iI6lgQ2usLk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install jieba（結巴）\n",
        "!pip install jieba\n",
        "\n",
        "# Get the Tokenization Dictionary for Traditional Chinese\n",
        "import os\n",
        "Dictionary_File = 'dict.txt.big'\n",
        "\n",
        "if not os.path.isfile(Dictionary_File):\n",
        "    os.system('wget https://raw.githubusercontent.com/cnchi/datasets/master/' + Dictionary_File)\n",
        "\n",
        "# Get the Stop Words File for Traditional Chinese\n",
        "StopWords_File = \"stopWords_big5.txt\"\n",
        "\n",
        "if not os.path.isfile(StopWords_File):\n",
        "    os.system('wget https://raw.githubusercontent.com/cnchi/datasets/master/' + StopWords_File)"
      ],
      "metadata": {
        "id": "bveqUjwbsSLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89c5396-ee65-4754-aece-458e0c3f2c75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (0.42.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "\n",
        "# Set Dictionary for Traditional Chinese\n",
        "# jieba.set_dictionary(Dictionary_File)\n",
        "\n",
        "# Tokenization\n",
        "result = list(jieba.cut(\"我喜歡跑步，你呢？\"))\n",
        "print(\"中文斷詞（有標點）：\", result)\n",
        "\n",
        "# Remove Stop Words from Set\n",
        "stopWords = set(\"$!&#%\\()+-*/_,. 　?:;'\\\"<=>^`|~[]{}’0123456789?_“”、。《》！，：；？「」（）\")\n",
        "print(\"中文斷詞（無標點）：\", [word for word in result if word not in stopWords])\n",
        "\n",
        "# Remove Stop Words from Files\n",
        "stopWords = set()\n",
        "with open(StopWords_File, \"rt\", encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "    line = line.strip() # Remove trailing \\n\n",
        "    stopWords.add(line)\n",
        "print(\"中文斷詞（更精簡）：\", [word for word in result if word not in stopWords])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYVzcb0Ei9RQ",
        "outputId": "55023439-1f21-4e4e-86b9-164ceeaad3d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "中文斷詞（有標點）： ['我', '喜歡', '跑步', '，', '你', '呢', '？']\n",
            "中文斷詞（無標點）： ['我', '喜歡', '跑步', '你', '呢']\n",
            "中文斷詞（更精簡）： ['喜歡', '跑步']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 文字數位化"
      ],
      "metadata": {
        "id": "PFDkjdHnwYRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Tokenizer object\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tk = Tokenizer(\n",
        "        num_words=None,\n",
        "        filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n",
        "        lower=True,\n",
        "        split=' ',\n",
        "        char_level=False,\n",
        "        oov_token='NiD'\n",
        "    )"
      ],
      "metadata": {
        "id": "cOGbDUBDwjkm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Mapping by Corpus\n",
        "corpus = [\"I love jogging, and you?\",\n",
        "      \"I love reading!\"]\n",
        "tk.fit_on_texts(corpus)\n",
        "\n",
        "# Show the Mapping Table\n",
        "print(tk.word_index)    # WORD vs. NUMBER\n",
        "print(tk.index_word)    # NUMBER vs. WORD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJrpvGcTwshB",
        "outputId": "0c955ac9-d139-40ba-8bc5-999f1493def9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NiD': 1, 'i': 2, 'love': 3, 'jogging': 4, 'and': 5, 'you': 6, 'reading': 7}\n",
            "{1: 'NiD', 2: 'i', 3: 'love', 4: 'jogging', 5: 'and', 6: 'you', 7: 'reading'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for Mapping Text into Sequence\n",
        "input_text = [\"I love jogging!\",\n",
        "        \"and I love reading, too!\"]\n",
        "\n",
        "seq = tk.texts_to_sequences(input_text)\n",
        "print(seq)\n",
        "\n",
        "# Test for Mapping Sequence into Text\n",
        "text = tk.sequences_to_texts(seq)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoxIPSDJxMN6",
        "outputId": "c1cd54b3-5b31-4810-ca2c-ba7fdde2fc96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3, 4], [5, 2, 3, 7, 1]]\n",
            "['i love jogging', 'and i love reading NiD']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 序列對齊（Sequence Alignment）"
      ],
      "metadata": {
        "id": "SnmGItjN079S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequence Padding Object\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padded_seq = pad_sequences(\n",
        "        sequences=seq,\n",
        "        maxlen=5,\n",
        "        dtype=\"int32\",\n",
        "        padding=\"pre\",\n",
        "        truncating=\"post\",\n",
        "        value=0\n",
        "    )\n",
        "\n",
        "print(padded_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHrnex8U0_3Q",
        "outputId": "353423f2-f6ac-49c5-802d-be3bd8626e86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 2 3 4]\n",
            " [5 2 3 7 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 編碼（Encoding）"
      ],
      "metadata": {
        "id": "v1SyEADl53UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"獨熱編碼 -------------\")\n",
        "print(to_categorical(padded_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzm6Ah9r57Nt",
        "outputId": "bf9350dc-8db6-4767-ff50-161dc682a968"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "獨熱編碼 -------------\n",
            "[[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Hot Encoding\n",
        "print(\"多熱編碼 -------------\")\n",
        "print(tk.texts_to_matrix(input_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsiLHOk_6O0w",
        "outputId": "1b86b0f1-97f0-4ce7-b597-080d4e21c2dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "多熱編碼 -------------\n",
            "[[0. 0. 1. 1. 1. 0. 0. 0.]\n",
            " [0. 1. 1. 1. 0. 1. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Embedding\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "emb = layers.Embedding(8, 3)\n",
        "\n",
        "# tf.constant(): Convert immediate values into tensor\n",
        "result = emb(tf.constant(padded_seq))\n",
        "print(\"詞向量嵌入 -------------\")\n",
        "print(result.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5IV6EE762b_",
        "outputId": "e65b679d-8a12-48d4-baa1-dec822b31fca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "詞向量嵌入 -------------\n",
            "[[[-2.8549397e-02 -1.6903508e-02  1.2396477e-02]\n",
            "  [-2.8549397e-02 -1.6903508e-02  1.2396477e-02]\n",
            "  [-3.8799167e-02  3.9433029e-02 -3.1143416e-02]\n",
            "  [ 3.7658226e-02 -2.5706291e-03  1.8841151e-02]\n",
            "  [-2.7186586e-02  2.7237687e-02 -2.7955068e-02]]\n",
            "\n",
            " [[ 1.7981578e-02 -7.7474862e-05  4.0822480e-02]\n",
            "  [-3.8799167e-02  3.9433029e-02 -3.1143416e-02]\n",
            "  [ 3.7658226e-02 -2.5706291e-03  1.8841151e-02]\n",
            "  [ 2.2235621e-02  6.1217919e-03 -1.4494441e-02]\n",
            "  [-3.1131400e-02  3.0269388e-02 -3.4443438e-02]]]\n"
          ]
        }
      ]
    }
  ]
}
